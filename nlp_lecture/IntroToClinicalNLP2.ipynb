{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c8b3ec86-ac5d-44c9-a5c5-ea12c7ccb113"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction to Natural Language Processing\n",
    "\n",
    "In this notebook, we'll go over some fundamental feature extraction concepts (very shallow NLP) using NLTK and scikit-learn.  This will lay the foundation for using machine learning with text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The term-document matrix representation of a corpus.\n",
    "\n",
    "This representation is extremely common for shallow NLP tasks, such as document-level classification.\n",
    "\n",
    "Also known as \"bag of words\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example unicode text\n",
    "docs = [u'The patient was seen for bird flu.', \n",
    "        u'The patient was seen for chickenpox.', \n",
    "        u'The patient was seen for dengue.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'bird',\n",
       " u'chickenpox',\n",
       " u'dengue',\n",
       " u'flu',\n",
       " u'for',\n",
       " u'patient',\n",
       " u'seen',\n",
       " u'the',\n",
       " u'was']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer(max_df=1., min_df=0,\n",
    "                                max_features=100,\n",
    "                                ngram_range=(1, 1),\n",
    "                                stop_words=None)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*tf*   is a sparse matrix.\n",
    "\n",
    "To see its contents, we'll use pandas to convert it to a table..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>chickenpox</th>\n",
       "      <th>dengue</th>\n",
       "      <th>flu</th>\n",
       "      <th>for</th>\n",
       "      <th>patient</th>\n",
       "      <th>seen</th>\n",
       "      <th>the</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bird  chickenpox  dengue  flu  for  patient  seen  the  was\n",
       "0     1           0       0    1    1        1     1    1    1\n",
       "1     0           1       0    0    1        1     1    1    1\n",
       "2     0           0       1    0    1        1     1    1    1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(tf.todense(),columns=tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop words.**  Words such as 'the', 'a', 'an', and may prepositions are often not so informative, and thus thrown out of the analysis as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>chickenpox</th>\n",
       "      <th>dengue</th>\n",
       "      <th>flu</th>\n",
       "      <th>patient</th>\n",
       "      <th>seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bird  chickenpox  dengue  flu  patient  seen\n",
       "0     1           0       0    1        1     1\n",
       "1     0           1       0    0        1     1\n",
       "2     0           0       1    0        1     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply stop words\n",
    "tf_vectorizer = CountVectorizer(max_df=1., min_df=0,\n",
    "                                max_features=100,\n",
    "                                ngram_range=(1, 1),\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "pd.DataFrame(tf.todense(),columns=tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**N-grams.** Single words or tokens are called unigrams, or 1-grams.  Sometimes unigrams simply do not capture enough information. In this case, we can take sequences of tokens.  \n",
    "\n",
    "For example, we want the matrix to record that \"bird flu\" was present in the first document, not just that the first document mentioned \"bird\" and that it also mentioned \"flu\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bird</th>\n",
       "      <th>bird flu</th>\n",
       "      <th>chickenpox</th>\n",
       "      <th>dengue</th>\n",
       "      <th>flu</th>\n",
       "      <th>patient</th>\n",
       "      <th>patient seen</th>\n",
       "      <th>seen</th>\n",
       "      <th>seen bird</th>\n",
       "      <th>seen chickenpox</th>\n",
       "      <th>seen dengue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bird  bird flu  chickenpox  dengue  flu  patient  patient seen  seen  \\\n",
       "0     1         1           0       0    1        1             1     1   \n",
       "1     0         0           1       0    0        1             1     1   \n",
       "2     0         0           0       1    0        1             1     1   \n",
       "\n",
       "   seen bird  seen chickenpox  seen dengue  \n",
       "0          1                0            0  \n",
       "1          0                1            0  \n",
       "2          0                0            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get the unigrams and bi-grams from the documents.\n",
    "tf_vectorizer = CountVectorizer(max_df=1., min_df=0,\n",
    "                                max_features=100,\n",
    "                                ngram_range=(1, 2),\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "pd.DataFrame(tf.todense(),columns=tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may want to add more complex features, such as tokens with their POS tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(., .)</th>\n",
       "      <th>(bird, NN)</th>\n",
       "      <th>(chickenpox, NN)</th>\n",
       "      <th>(dengue, NN)</th>\n",
       "      <th>(flu, NN)</th>\n",
       "      <th>(for, IN)</th>\n",
       "      <th>(patient, NN)</th>\n",
       "      <th>(seen, VBN)</th>\n",
       "      <th>(the, DT)</th>\n",
       "      <th>(was, VBD)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   (., .)  (bird, NN)  (chickenpox, NN)  (dengue, NN)  (flu, NN)  (for, IN)  \\\n",
       "0       1           1                 0             0          1          1   \n",
       "1       1           0                 1             0          0          1   \n",
       "2       1           0                 0             1          0          1   \n",
       "\n",
       "   (patient, NN)  (seen, VBN)  (the, DT)  (was, VBD)  \n",
       "0              1            1          1           1  \n",
       "1              1            1          1           1  \n",
       "2              1            1          1           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "def tokenize_and_tag(doc):\n",
    "     return nltk.pos_tag(nltk.word_tokenize(doc))\n",
    "    \n",
    "tf_vectorizer = CountVectorizer(max_df=1., min_df=1,\n",
    "                                max_features=100,\n",
    "                                ngram_range=(1, 1),\n",
    "                                tokenizer=tokenize_and_tag)\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(docs)\n",
    "pd.DataFrame(tf.todense(),columns=tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now look at the 20 news groups data.  Check scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the 20 newsgroups Corpus (just the train set for now)\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='train',\n",
    "                          categories=('rec.autos',\n",
    "                             'rec.motorcycles',\n",
    "                             'rec.sport.baseball',\n",
    "                             'rec.sport.hockey'),\n",
    "                          remove=('headers', 'footers', 'quotes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1-grams up to 1-grams on the first 500 news groups documents yields 9328 features\n",
      "Using 1-grams up to 2-grams on the first 500 news groups documents yields 39452 features\n",
      "Using 1-grams up to 3-grams on the first 500 news groups documents yields 71233 features\n",
      "Using 1-grams up to 4-grams on the first 500 news groups documents yields 102880 features\n"
     ]
    }
   ],
   "source": [
    "for n in range(1,5):\n",
    "    tf_vectorizer = CountVectorizer(max_df=1., min_df=1,\n",
    "                                    max_features=999999,\n",
    "                                    ngram_range=(1, n),\n",
    "                                    stop_words='english')\n",
    "    tf = tf_vectorizer.fit_transform(news.data[:500])\n",
    "    print \"Using 1-grams up to %d-grams on the first 500 news groups documents yields %d features\" % (n,tf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use 1-3 - grams to predict the newsgroups category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigrams data shape =  (2389, 1000)\n"
     ]
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=1., min_df=10,\n",
    "                                max_features=1000,\n",
    "                                ngram_range=(1, 3),\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(news.data)\n",
    "print \"bigrams data shape = \", tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB(alpha=.01)\n",
    "clf.fit(tf, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'000',\n",
       " u'01',\n",
       " u'02',\n",
       " u'03',\n",
       " u'04',\n",
       " u'05',\n",
       " u'06',\n",
       " u'10',\n",
       " u'100',\n",
       " u'11',\n",
       " u'110',\n",
       " u'12',\n",
       " u'13',\n",
       " u'130',\n",
       " u'14',\n",
       " u'15',\n",
       " u'150',\n",
       " u'16',\n",
       " u'17',\n",
       " u'18',\n",
       " u'19',\n",
       " u'1988',\n",
       " u'1990',\n",
       " u'1991',\n",
       " u'1992',\n",
       " u'1993',\n",
       " u'1st',\n",
       " u'20',\n",
       " u'200',\n",
       " u'21',\n",
       " u'22',\n",
       " u'23',\n",
       " u'24',\n",
       " u'25',\n",
       " u'250',\n",
       " u'26',\n",
       " u'27',\n",
       " u'28',\n",
       " u'29',\n",
       " u'2nd',\n",
       " u'30',\n",
       " u'300',\n",
       " u'31',\n",
       " u'32',\n",
       " u'33',\n",
       " u'34',\n",
       " u'35',\n",
       " u'36',\n",
       " u'37',\n",
       " u'38',\n",
       " u'39',\n",
       " u'3rd',\n",
       " u'40',\n",
       " u'400',\n",
       " u'41',\n",
       " u'42',\n",
       " u'43',\n",
       " u'44',\n",
       " u'45',\n",
       " u'46',\n",
       " u'47',\n",
       " u'48',\n",
       " u'49',\n",
       " u'50',\n",
       " u'500',\n",
       " u'51',\n",
       " u'52',\n",
       " u'53',\n",
       " u'54',\n",
       " u'55',\n",
       " u'56',\n",
       " u'57',\n",
       " u'58',\n",
       " u'59',\n",
       " u'60',\n",
       " u'600',\n",
       " u'61',\n",
       " u'62',\n",
       " u'63',\n",
       " u'64',\n",
       " u'65',\n",
       " u'66',\n",
       " u'67',\n",
       " u'68',\n",
       " u'69',\n",
       " u'70',\n",
       " u'71',\n",
       " u'72',\n",
       " u'73',\n",
       " u'74',\n",
       " u'75',\n",
       " u'76',\n",
       " u'77',\n",
       " u'78',\n",
       " u'79',\n",
       " u'80',\n",
       " u'81',\n",
       " u'82',\n",
       " u'83',\n",
       " u'84',\n",
       " u'85',\n",
       " u'86',\n",
       " u'87',\n",
       " u'88',\n",
       " u'89',\n",
       " u'90',\n",
       " u'91',\n",
       " u'91 92',\n",
       " u'92',\n",
       " u'93',\n",
       " u'94',\n",
       " u'95',\n",
       " u'97',\n",
       " u'99',\n",
       " u'__',\n",
       " u'___',\n",
       " u'abc',\n",
       " u'ability',\n",
       " u'able',\n",
       " u'abs',\n",
       " u'accident',\n",
       " u'according',\n",
       " u'actually',\n",
       " u'add',\n",
       " u'address',\n",
       " u'advice',\n",
       " u'age',\n",
       " u'ago',\n",
       " u'agree',\n",
       " u'ahead',\n",
       " u'ahl',\n",
       " u'air',\n",
       " u'al',\n",
       " u'allowed',\n",
       " u'alomar',\n",
       " u'america',\n",
       " u'american',\n",
       " u'amour',\n",
       " u'andrew',\n",
       " u'angeles',\n",
       " u'announced',\n",
       " u'answer',\n",
       " u'anybody',\n",
       " u'appreciated',\n",
       " u'april',\n",
       " u'area',\n",
       " u'aren',\n",
       " u'arena',\n",
       " u'argument',\n",
       " u'article',\n",
       " u'ask',\n",
       " u'asked',\n",
       " u'atlanta',\n",
       " u'auto',\n",
       " u'autos',\n",
       " u'available',\n",
       " u'average',\n",
       " u'away',\n",
       " u'bad',\n",
       " u'ball',\n",
       " u'baltimore',\n",
       " u'base',\n",
       " u'baseball',\n",
       " u'based',\n",
       " u'bat',\n",
       " u'battery',\n",
       " u'bay',\n",
       " u'beat',\n",
       " u'believe',\n",
       " u'best',\n",
       " u'bet',\n",
       " u'better',\n",
       " u'big',\n",
       " u'biggest',\n",
       " u'bike',\n",
       " u'bikes',\n",
       " u'bit',\n",
       " u'black',\n",
       " u'blue',\n",
       " u'blues',\n",
       " u'bmw',\n",
       " u'bob',\n",
       " u'bobby',\n",
       " u'body',\n",
       " u'book',\n",
       " u'bos',\n",
       " u'boston',\n",
       " u'bought',\n",
       " u'box',\n",
       " u'brake',\n",
       " u'brakes',\n",
       " u'braves',\n",
       " u'break',\n",
       " u'brian',\n",
       " u'brind',\n",
       " u'brind amour',\n",
       " u'bring',\n",
       " u'brown',\n",
       " u'bruins',\n",
       " u'btw',\n",
       " u'buf',\n",
       " u'buffalo',\n",
       " u'business',\n",
       " u'buy',\n",
       " u'buying',\n",
       " u'ca',\n",
       " u'cal',\n",
       " u'calgary',\n",
       " u'california',\n",
       " u'called',\n",
       " u'came',\n",
       " u'canada',\n",
       " u'canadian',\n",
       " u'canucks',\n",
       " u'caps',\n",
       " u'captain',\n",
       " u'car',\n",
       " u'care',\n",
       " u'career',\n",
       " u'carry',\n",
       " u'cars',\n",
       " u'case',\n",
       " u'catcher',\n",
       " u'caught',\n",
       " u'cause',\n",
       " u'center',\n",
       " u'certain',\n",
       " u'certainly',\n",
       " u'championships',\n",
       " u'chance',\n",
       " u'chances',\n",
       " u'change',\n",
       " u'changed',\n",
       " u'check',\n",
       " u'chi',\n",
       " u'chicago',\n",
       " u'choice',\n",
       " u'chris',\n",
       " u'cincinnati',\n",
       " u'city',\n",
       " u'claim',\n",
       " u'clark',\n",
       " u'clean',\n",
       " u'clear',\n",
       " u'clemens',\n",
       " u'cleveland',\n",
       " u'close',\n",
       " u'club',\n",
       " u'clutch',\n",
       " u'coach',\n",
       " u'colorado',\n",
       " u'com',\n",
       " u'come',\n",
       " u'comes',\n",
       " u'coming',\n",
       " u'comment',\n",
       " u'comments',\n",
       " u'company',\n",
       " u'completely',\n",
       " u'conference',\n",
       " u'consider',\n",
       " u'considered',\n",
       " u'considering',\n",
       " u'contact',\n",
       " u'contract',\n",
       " u'control',\n",
       " u'corner',\n",
       " u'cost',\n",
       " u'costs',\n",
       " u'couldn',\n",
       " u'couple',\n",
       " u'course',\n",
       " u'cover',\n",
       " u'coverage',\n",
       " u'cross',\n",
       " u'cs',\n",
       " u'cubs',\n",
       " u'cup',\n",
       " u'current',\n",
       " u'currently',\n",
       " u'cut',\n",
       " u'dallas',\n",
       " u'damage',\n",
       " u'damn',\n",
       " u'date',\n",
       " u'dave',\n",
       " u'david',\n",
       " u'day',\n",
       " u'days',\n",
       " u'dead',\n",
       " u'deal',\n",
       " u'dealer',\n",
       " u'decent',\n",
       " u'decided',\n",
       " u'defense',\n",
       " u'defenseman',\n",
       " u'defensive',\n",
       " u'deleted',\n",
       " u'designed',\n",
       " u'det',\n",
       " u'detroit',\n",
       " u'devils',\n",
       " u'did',\n",
       " u'didn',\n",
       " u'difference',\n",
       " u'different',\n",
       " u'dineen',\n",
       " u'discussion',\n",
       " u'division',\n",
       " u'dod',\n",
       " u'dodgers',\n",
       " u'does',\n",
       " u'doesn',\n",
       " u'dog',\n",
       " u'doing',\n",
       " u'don',\n",
       " u'don know',\n",
       " u'don think',\n",
       " u'door',\n",
       " u'double',\n",
       " u'doubt',\n",
       " u'draft',\n",
       " u'drive',\n",
       " u'driven',\n",
       " u'driver',\n",
       " u'drivers',\n",
       " u'driving',\n",
       " u'earlier',\n",
       " u'early',\n",
       " u'easily',\n",
       " u'east',\n",
       " u'easy',\n",
       " u'ed',\n",
       " u'edm',\n",
       " u'edmonton',\n",
       " u'edu',\n",
       " u'effect',\n",
       " u'email',\n",
       " u'end',\n",
       " u'engine',\n",
       " u'era',\n",
       " u'eric',\n",
       " u'especially',\n",
       " u'espn',\n",
       " u'europe',\n",
       " u'european',\n",
       " u'exactly',\n",
       " u'example',\n",
       " u'excellent',\n",
       " u'expansion',\n",
       " u'expect',\n",
       " u'expected',\n",
       " u'expensive',\n",
       " u'experience',\n",
       " u'extra',\n",
       " u'face',\n",
       " u'fact',\n",
       " u'fairly',\n",
       " u'fan',\n",
       " u'fans',\n",
       " u'far',\n",
       " u'fast',\n",
       " u'favorite',\n",
       " u'feel',\n",
       " u'feet',\n",
       " u'field',\n",
       " u'final',\n",
       " u'finally',\n",
       " u'finals',\n",
       " u'fine',\n",
       " u'finish',\n",
       " u'finland',\n",
       " u'fit',\n",
       " u'flame',\n",
       " u'flames',\n",
       " u'florida',\n",
       " u'flyers',\n",
       " u'following',\n",
       " u'foot',\n",
       " u'force',\n",
       " u'ford',\n",
       " u'forget',\n",
       " u'forward',\n",
       " u'francis',\n",
       " u'frank',\n",
       " u'free',\n",
       " u'friday',\n",
       " u'friend',\n",
       " u'fuel',\n",
       " u'fun',\n",
       " u'future',\n",
       " u'galley',\n",
       " u'game',\n",
       " u'games',\n",
       " u'gas',\n",
       " u'gave',\n",
       " u'gear',\n",
       " u'general',\n",
       " u'generally',\n",
       " u'germany',\n",
       " u'gets',\n",
       " u'getting',\n",
       " u'giants',\n",
       " u'gilmour',\n",
       " u'given',\n",
       " u'giving',\n",
       " u'gm',\n",
       " u'goal',\n",
       " u'goalie',\n",
       " u'goals',\n",
       " u'goes',\n",
       " u'going',\n",
       " u'gone',\n",
       " u'good',\n",
       " u'got',\n",
       " u'great',\n",
       " u'gretzky',\n",
       " u'ground',\n",
       " u'group',\n",
       " u'guess',\n",
       " u'guy',\n",
       " u'guys',\n",
       " u'habs',\n",
       " u'half',\n",
       " u'hall',\n",
       " u'hand',\n",
       " u'happen',\n",
       " u'happened',\n",
       " u'happy',\n",
       " u'hard',\n",
       " u'harley',\n",
       " u'hartford',\n",
       " u'haven',\n",
       " u'having',\n",
       " u'hawks',\n",
       " u'head',\n",
       " u'hear',\n",
       " u'heard',\n",
       " u'hell',\n",
       " u'helmet',\n",
       " u'help',\n",
       " u'hey',\n",
       " u'hi',\n",
       " u'high',\n",
       " u'higher',\n",
       " u'history',\n",
       " u'hit',\n",
       " u'hits',\n",
       " u'hitter',\n",
       " u'hitting',\n",
       " u'hockey',\n",
       " u'home',\n",
       " u'honda',\n",
       " u'hope',\n",
       " u'hot',\n",
       " u'houston',\n",
       " u'hp',\n",
       " u'hr',\n",
       " u'hurt',\n",
       " u'ice',\n",
       " u'idea',\n",
       " u'imho',\n",
       " u'important',\n",
       " u'include',\n",
       " u'including',\n",
       " u'info',\n",
       " u'information',\n",
       " u'injury',\n",
       " u'innings',\n",
       " u'inside',\n",
       " u'instead',\n",
       " u'insurance',\n",
       " u'interested',\n",
       " u'interesting',\n",
       " u'islanders',\n",
       " u'isn',\n",
       " u'issue',\n",
       " u'jagr',\n",
       " u'james',\n",
       " u'jays',\n",
       " u'jeff',\n",
       " u'jersey',\n",
       " u'jets',\n",
       " u'jewish',\n",
       " u'jim',\n",
       " u'job',\n",
       " u'joe',\n",
       " u'john',\n",
       " u'jose',\n",
       " u'june',\n",
       " u'just',\n",
       " u'keith',\n",
       " u'kept',\n",
       " u'key',\n",
       " u'kill',\n",
       " u'kind',\n",
       " u'king',\n",
       " u'kings',\n",
       " u'knew',\n",
       " u'know',\n",
       " u'known',\n",
       " u'knows',\n",
       " u'la',\n",
       " u'lane',\n",
       " u'large',\n",
       " u'late',\n",
       " u'later',\n",
       " u'law',\n",
       " u'lead',\n",
       " u'leads',\n",
       " u'leafs',\n",
       " u'league',\n",
       " u'learn',\n",
       " u'leave',\n",
       " u'left',\n",
       " u'lemieux',\n",
       " u'let',\n",
       " u'level',\n",
       " u'life',\n",
       " u'light',\n",
       " u'lights',\n",
       " u'like',\n",
       " u'likely',\n",
       " u'lindros',\n",
       " u'line',\n",
       " u'lines',\n",
       " u'list',\n",
       " u'little',\n",
       " u'live',\n",
       " u'll',\n",
       " u'local',\n",
       " u'lock',\n",
       " u'long',\n",
       " u'longer',\n",
       " u'look',\n",
       " u'looked',\n",
       " u'looking',\n",
       " u'looks',\n",
       " u'looks like',\n",
       " u'lopez',\n",
       " u'los',\n",
       " u'los angeles',\n",
       " u'lose',\n",
       " u'loss',\n",
       " u'lost',\n",
       " u'lot',\n",
       " u'lots',\n",
       " u'louis',\n",
       " u'love',\n",
       " u'low',\n",
       " u'lower',\n",
       " u'luck',\n",
       " u'mail',\n",
       " u'mailing',\n",
       " u'mailing list',\n",
       " u'maine',\n",
       " u'major',\n",
       " u'make',\n",
       " u'makes',\n",
       " u'making',\n",
       " u'man',\n",
       " u'manager',\n",
       " u'manual',\n",
       " u'maple',\n",
       " u'maple leafs',\n",
       " u'mark',\n",
       " u'market',\n",
       " u'match',\n",
       " u'matter',\n",
       " u'maybe',\n",
       " u'mean',\n",
       " u'means',\n",
       " u'mention',\n",
       " u'mentioned',\n",
       " u'mets',\n",
       " u'mid',\n",
       " u'middle',\n",
       " u'mike',\n",
       " u'miles',\n",
       " u'milwaukee',\n",
       " u'min',\n",
       " u'mind',\n",
       " u'minnesota',\n",
       " u'minor',\n",
       " u'minute',\n",
       " u'minutes',\n",
       " u'missed',\n",
       " u'model',\n",
       " u'models',\n",
       " u'mon',\n",
       " u'money',\n",
       " u'month',\n",
       " u'months',\n",
       " u'montreal',\n",
       " u'morning',\n",
       " u'morris',\n",
       " u'motor',\n",
       " u'motorcycle',\n",
       " u'motorcycles',\n",
       " u'moved',\n",
       " u'mph',\n",
       " u'murphy',\n",
       " u'murray',\n",
       " u'mvp',\n",
       " u'names',\n",
       " u'national',\n",
       " u'near',\n",
       " u'need',\n",
       " u'needs',\n",
       " u'net',\n",
       " u'new',\n",
       " u'new jersey',\n",
       " u'new york',\n",
       " u'news',\n",
       " u'nhl',\n",
       " u'nice',\n",
       " u'night',\n",
       " u'nj',\n",
       " u'nl',\n",
       " u'non',\n",
       " u'normal',\n",
       " u'north',\n",
       " u'note',\n",
       " u'noticed',\n",
       " u'number',\n",
       " u'numbers',\n",
       " u'ny',\n",
       " u'nyi',\n",
       " u'nyr',\n",
       " u'obviously',\n",
       " u'offense',\n",
       " u'offensive',\n",
       " u'oh',\n",
       " u'oil',\n",
       " u'oilers',\n",
       " u'ok',\n",
       " u'okay',\n",
       " u'old',\n",
       " u'ones',\n",
       " u'open',\n",
       " u'opinion',\n",
       " u'opinions',\n",
       " u'order',\n",
       " u'original',\n",
       " u'ott',\n",
       " u'ottawa',\n",
       " u'outside',\n",
       " u'owner',\n",
       " u'owners',\n",
       " u'paint',\n",
       " u'park',\n",
       " u'parts',\n",
       " u'pass',\n",
       " u'past',\n",
       " u'patrick',\n",
       " u'paul',\n",
       " u'pay',\n",
       " u'penalties',\n",
       " u'penalty',\n",
       " u'penguins',\n",
       " u'pens',\n",
       " u'people',\n",
       " u'percentage',\n",
       " u'performance',\n",
       " u'period',\n",
       " u'person',\n",
       " u'peter',\n",
       " u'phi',\n",
       " u'philadelphia',\n",
       " u'phillies',\n",
       " u'phone',\n",
       " u'pick',\n",
       " u'picked',\n",
       " u'piece',\n",
       " u'pirates',\n",
       " u'pit',\n",
       " u'pitch',\n",
       " u'pitched',\n",
       " u'pitcher',\n",
       " u'pitchers',\n",
       " u'pitching',\n",
       " u'pittsburgh',\n",
       " u'place',\n",
       " u'places',\n",
       " u'plastic',\n",
       " u'play',\n",
       " u'played',\n",
       " u'player',\n",
       " u'players',\n",
       " u'playing',\n",
       " u'playoff',\n",
       " u'playoffs',\n",
       " u'plays',\n",
       " u'plus',\n",
       " u'point',\n",
       " u'points',\n",
       " u'pool',\n",
       " u'position',\n",
       " u'possible',\n",
       " u'post',\n",
       " u'posted',\n",
       " u'posting',\n",
       " u'power',\n",
       " u'power play',\n",
       " u'pp',\n",
       " u'president',\n",
       " u'pressure',\n",
       " u'pretty',\n",
       " u'previous',\n",
       " u'price',\n",
       " u'probably',\n",
       " u'problem',\n",
       " u'problems',\n",
       " u'pts',\n",
       " u'puck',\n",
       " u'pull',\n",
       " u'quality',\n",
       " u'que',\n",
       " u'quebec',\n",
       " u'question',\n",
       " u'questions',\n",
       " u'quickly',\n",
       " u'quite',\n",
       " u'radar',\n",
       " u'radio',\n",
       " u'rangers',\n",
       " u'rbi',\n",
       " u'read',\n",
       " u'reading',\n",
       " u'real',\n",
       " u'really',\n",
       " u'rear',\n",
       " u'reason',\n",
       " u'rec',\n",
       " u'rec autos',\n",
       " u'recchi',\n",
       " u'recent',\n",
       " u'recently',\n",
       " u'record',\n",
       " u'red',\n",
       " u'red sox',\n",
       " u'red wings',\n",
       " u'reds',\n",
       " u'regular',\n",
       " u'regular season',\n",
       " u'remember',\n",
       " u'replace',\n",
       " u'replaced',\n",
       " u'request',\n",
       " u'rest',\n",
       " u'ride',\n",
       " u'rider',\n",
       " u'riders',\n",
       " u'riding',\n",
       " u'right',\n",
       " u'road',\n",
       " u'rob',\n",
       " u'rochester',\n",
       " u'roger',\n",
       " u'ron',\n",
       " u'rookie',\n",
       " u'room',\n",
       " u'round',\n",
       " u'roy',\n",
       " u'rule',\n",
       " u'rules',\n",
       " u'run',\n",
       " u'running',\n",
       " u'runs',\n",
       " u'ryan',\n",
       " u'sabres',\n",
       " u'safety',\n",
       " u'said',\n",
       " u'san',\n",
       " u'san jose',\n",
       " u'sanderson',\n",
       " u'saturn',\n",
       " u'save',\n",
       " u'saves',\n",
       " u'saw',\n",
       " u'say',\n",
       " u'saying',\n",
       " u'says',\n",
       " u'school',\n",
       " u'score',\n",
       " u'scored',\n",
       " u'scorer',\n",
       " u'scores',\n",
       " u'scoring',\n",
       " u'scott',\n",
       " u'season',\n",
       " u'seat',\n",
       " u'seats',\n",
       " u'second',\n",
       " u'second period',\n",
       " u'seconds',\n",
       " u'section',\n",
       " u'seen',\n",
       " u'sell',\n",
       " u'selling',\n",
       " u'senators',\n",
       " u'send',\n",
       " u'sense',\n",
       " u'sent',\n",
       " u'series',\n",
       " u'seriously',\n",
       " u'service',\n",
       " u'set',\n",
       " u'sharks',\n",
       " u'shift',\n",
       " u'short',\n",
       " u'shot',\n",
       " u'shots',\n",
       " u'sign',\n",
       " u'similar',\n",
       " u'simple',\n",
       " u'simply',\n",
       " u'single',\n",
       " u'situation',\n",
       " u'size',\n",
       " u'sj',\n",
       " u'slightly',\n",
       " u'slow',\n",
       " u'small',\n",
       " u'smith',\n",
       " u'snow',\n",
       " u'soderstrom',\n",
       " u'sold',\n",
       " u'solid',\n",
       " u'somebody',\n",
       " u'soon',\n",
       " u'sorry',\n",
       " u'sort',\n",
       " u'sound',\n",
       " u'sounds',\n",
       " u'south',\n",
       " u'sox',\n",
       " u'special',\n",
       " u'speed',\n",
       " u'sport',\n",
       " u'sports',\n",
       " u'spot',\n",
       " u'spring',\n",
       " u'st',\n",
       " u'st louis',\n",
       " u'stadium',\n",
       " u'staff',\n",
       " u'stand',\n",
       " u'standard',\n",
       " u'standings',\n",
       " u'stanley',\n",
       " u'stanley cup',\n",
       " u'star',\n",
       " u'stars',\n",
       " u'start',\n",
       " u'started',\n",
       " u'starting',\n",
       " u'starts',\n",
       " u'state',\n",
       " u'stats',\n",
       " u'steering',\n",
       " u'steve',\n",
       " u'stevens',\n",
       " u'stick',\n",
       " u'stl',\n",
       " u'stop',\n",
       " u'stopped',\n",
       " u'story',\n",
       " u'straight',\n",
       " u'street',\n",
       " u'strong',\n",
       " u'stuff',\n",
       " u'stupid',\n",
       " u'subject',\n",
       " u'suck',\n",
       " u'sun',\n",
       " u'sunday',\n",
       " u'sure',\n",
       " u'suspension',\n",
       " u'sweden',\n",
       " u'taken',\n",
       " u'takes',\n",
       " u'taking',\n",
       " u'talent',\n",
       " u'talk',\n",
       " u'talking',\n",
       " u'tampa',\n",
       " u'tampa bay',\n",
       " u'tank',\n",
       " u'tb',\n",
       " u'team',\n",
       " u'teams',\n",
       " u'tell',\n",
       " u'terrible',\n",
       " u'test',\n",
       " u'texas',\n",
       " u'thanks',\n",
       " u'thing',\n",
       " u'things',\n",
       " u'think',\n",
       " u'thinking',\n",
       " u'thomas',\n",
       " u'thought',\n",
       " u'throttle',\n",
       " u'throw',\n",
       " u'ticket',\n",
       " u'tie',\n",
       " u'time',\n",
       " u'times',\n",
       " u'tire',\n",
       " u'tires',\n",
       " u'today',\n",
       " u'told',\n",
       " u'tom',\n",
       " u'tommy',\n",
       " u'took',\n",
       " u'tor',\n",
       " u'toronto',\n",
       " u'torque',\n",
       " u'total',\n",
       " u'toyota',\n",
       " u'trade',\n",
       " u'traded',\n",
       " u'traffic',\n",
       " u'transmission',\n",
       " u'tried',\n",
       " u'trouble',\n",
       " u'truck',\n",
       " u'true',\n",
       " u'try',\n",
       " u'trying',\n",
       " u'turn',\n",
       " u'turned',\n",
       " u'tv',\n",
       " u'type',\n",
       " u'understand',\n",
       " u'unfortunately',\n",
       " u'university',\n",
       " u'unless',\n",
       " u'usa',\n",
       " u'use',\n",
       " u'used',\n",
       " u'useful',\n",
       " u'using',\n",
       " u'usually',\n",
       " u'value',\n",
       " u'van',\n",
       " u'vancouver',\n",
       " u've',\n",
       " u've seen',\n",
       " u'vehicle',\n",
       " u'vs',\n",
       " u'vw',\n",
       " u'wait',\n",
       " u'want',\n",
       " u'wanted',\n",
       " u'wants',\n",
       " u'washington',\n",
       " u'wasn',\n",
       " u'watch',\n",
       " u'watching',\n",
       " u'way',\n",
       " u'week',\n",
       " u'weekend',\n",
       " u'weeks',\n",
       " u'weight',\n",
       " u'went',\n",
       " u'west',\n",
       " u'wheel',\n",
       " u'white',\n",
       " u'win',\n",
       " u'wings',\n",
       " u'winner',\n",
       " u'winning',\n",
       " u'winnipeg',\n",
       " u'wins',\n",
       " u'women',\n",
       " u'won',\n",
       " u'wonder',\n",
       " u'wondering',\n",
       " u'word',\n",
       " u'work',\n",
       " u'working',\n",
       " u'world',\n",
       " u'worse',\n",
       " u'worst',\n",
       " u'worth',\n",
       " u'wouldn',\n",
       " u'wrong',\n",
       " u'yankees',\n",
       " u'yeah',\n",
       " u'year',\n",
       " u'years',\n",
       " u'years ago',\n",
       " u'yes',\n",
       " u'yesterday',\n",
       " u'york',\n",
       " u'young',\n",
       " u'zone']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos: \n",
      "\t think\n",
      "\t know\n",
      "\t engine\n",
      "\t new\n",
      "\t good\n",
      "\t don\n",
      "\t just\n",
      "\t like\n",
      "\t cars\n",
      "\t car\n",
      "rec.motorcycles: \n",
      "\t time\n",
      "\t motorcycle\n",
      "\t ride\n",
      "\t good\n",
      "\t know\n",
      "\t don\n",
      "\t dod\n",
      "\t like\n",
      "\t just\n",
      "\t bike\n",
      "rec.sport.baseball: \n",
      "\t games\n",
      "\t like\n",
      "\t just\n",
      "\t 00\n",
      "\t don\n",
      "\t think\n",
      "\t team\n",
      "\t good\n",
      "\t game\n",
      "\t year\n",
      "rec.sport.hockey: \n",
      "\t 12\n",
      "\t 11\n",
      "\t season\n",
      "\t 55\n",
      "\t play\n",
      "\t 25\n",
      "\t hockey\n",
      "\t 10\n",
      "\t game\n",
      "\t team\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def show_top10(classifier, vectorizer, categories):\n",
    "    feature_names = np.asarray(vectorizer.get_feature_names())\n",
    "    for i, category in enumerate(categories):\n",
    "        top10 = np.argsort(classifier.coef_[i])[-10:]\n",
    "        print(\"%s: \" % category)\n",
    "        for j in top10:\n",
    "            print(\"\\t %s\" % feature_names[j])\n",
    "\n",
    "show_top10(clf, tf_vectorizer, news.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "news_test = fetch_20newsgroups(subset='test',\n",
    "                               categories=('rec.autos',\n",
    "                                 'rec.motorcycles',\n",
    "                                 'rec.sport.baseball',\n",
    "                                 'rec.sport.hockey'),\n",
    "                               remove=('headers', 'footers', 'quotes'))\n",
    "tf_test = tf_vectorizer.transform(news_test.data)\n",
    "pred = clf.predict(tf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "         rec.autos       0.75      0.78      0.77       396\n",
      "   rec.motorcycles       0.78      0.76      0.77       398\n",
      "rec.sport.baseball       0.79      0.81      0.80       397\n",
      "  rec.sport.hockey       0.77      0.75      0.76       399\n",
      "\n",
      "       avg / total       0.77      0.77      0.77      1590\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(news_test.target, pred, target_names=news.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "16df8b59-5bc2-4d5b-ba3f-a178744ac923": {
     "id": "16df8b59-5bc2-4d5b-ba3f-a178744ac923",
     "prev": "aa3ee3b4-556f-4ea8-b8a4-e51c983ca770",
     "regions": {
      "ab3fc3b2-a4b3-4943-9aa5-825ac7088ff5": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "1fd934b5-bc66-4e5d-b1f1-b761fd7c1b3b",
        "part": "source"
       },
       "id": "ab3fc3b2-a4b3-4943-9aa5-825ac7088ff5"
      }
     }
    },
    "30f3fb19-fbe3-4d69-abd5-7f8b7f40efd8": {
     "id": "30f3fb19-fbe3-4d69-abd5-7f8b7f40efd8",
     "prev": "16df8b59-5bc2-4d5b-ba3f-a178744ac923",
     "regions": {
      "4e25a3a0-2bae-441b-8b54-169061b9f3e3": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "695365a2-6432-4ccb-a0f7-102a4ada25a2",
        "part": "source"
       },
       "id": "4e25a3a0-2bae-441b-8b54-169061b9f3e3"
      }
     }
    },
    "7a2c2b31-a6ac-4207-9c14-d99373562671": {
     "id": "7a2c2b31-a6ac-4207-9c14-d99373562671",
     "prev": "b5748b9e-f422-4eb4-97d8-013656ea71ea",
     "regions": {
      "522b018f-71db-441b-acea-9bc6ac6e8fab": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.05,
        "y": 0.1
       },
       "content": {
        "cell": "a3e854d4-afd1-407b-ad3b-3388adfa5c59",
        "part": "source"
       },
       "id": "522b018f-71db-441b-acea-9bc6ac6e8fab"
      },
      "75c3539a-d2df-44a7-9d7b-b782086041b6": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.5,
        "y": 0.1
       },
       "content": {
        "cell": "39a062c0-53d9-4836-b7f2-d863557c3842",
        "part": "whole"
       },
       "id": "75c3539a-d2df-44a7-9d7b-b782086041b6"
      }
     }
    },
    "8ee2439b-8d0e-45af-a452-b807bd7d1cb0": {
     "id": "8ee2439b-8d0e-45af-a452-b807bd7d1cb0",
     "prev": null,
     "regions": {
      "ff2c3bf2-9512-4de8-a236-39de1db8813a": {
       "attrs": {
        "height": 0.8,
        "width": 0.45,
        "x": 0.05,
        "y": 0.1
       },
       "content": {
        "cell": "c8b3ec86-ac5d-44c9-a5c5-ea12c7ccb113",
        "part": "source"
       },
       "id": "ff2c3bf2-9512-4de8-a236-39de1db8813a"
      }
     }
    },
    "aa3ee3b4-556f-4ea8-b8a4-e51c983ca770": {
     "id": "aa3ee3b4-556f-4ea8-b8a4-e51c983ca770",
     "prev": "8ee2439b-8d0e-45af-a452-b807bd7d1cb0",
     "regions": {
      "18dde78c-c9d1-433b-b821-25954e65efc6": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "0c03e049-d629-440b-85bd-ef2883ca61ad",
        "part": "source"
       },
       "id": "18dde78c-c9d1-433b-b821-25954e65efc6"
      }
     }
    },
    "b5748b9e-f422-4eb4-97d8-013656ea71ea": {
     "id": "b5748b9e-f422-4eb4-97d8-013656ea71ea",
     "prev": "30f3fb19-fbe3-4d69-abd5-7f8b7f40efd8",
     "regions": {
      "cf8a6c53-278d-4d91-8131-8a73a4e6ef28": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "a3e854d4-afd1-407b-ad3b-3388adfa5c59",
        "part": "source"
       },
       "id": "cf8a6c53-278d-4d91-8131-8a73a4e6ef28"
      }
     }
    },
    "ffce2803-6b15-4098-9995-74f1fbbb9307": {
     "id": "ffce2803-6b15-4098-9995-74f1fbbb9307",
     "prev": "7a2c2b31-a6ac-4207-9c14-d99373562671",
     "regions": {
      "0f1c7dd4-d298-45cf-8c6a-57b877272ae8": {
       "attrs": {
        "height": 1,
        "width": 1,
        "x": 0,
        "y": 0
       },
       "content": {
        "cell": "39a062c0-53d9-4836-b7f2-d863557c3842",
        "part": "whole"
       },
       "id": "0f1c7dd4-d298-45cf-8c6a-57b877272ae8"
      }
     }
    }
   },
   "themes": {
    "default": "074f5102-975e-42ad-a86d-e888569a1bb0",
    "theme": {
     "074f5102-975e-42ad-a86d-e888569a1bb0": {
      "backgrounds": {
       "dc7afa04-bf90-40b1-82a5-726e3cff5267": {
        "background-color": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "id": "dc7afa04-bf90-40b1-82a5-726e3cff5267"
       }
      },
      "id": "074f5102-975e-42ad-a86d-e888569a1bb0",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         197,
         226,
         245
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "a": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c"
       },
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 8
       },
       "h2": {
        "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "font-family": "Merriweather",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "li": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-size": 3.25
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
       "font-family": "Lato",
       "font-size": 4
      }
     },
     "870622fb-0a9f-4a9f-9d04-a55735a537a8": {
      "id": "870622fb-0a9f-4a9f-9d04-a55735a537a8",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
